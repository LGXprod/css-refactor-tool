{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import colorsys\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveAsJson(filePath, data):\n",
    "    with open(filePath, 'w') as fp:\n",
    "        json.dump(data, fp, indent=2)\n",
    "\n",
    "def getDefaultStyleProps(style):\n",
    "    return {\n",
    "        \"style\": style,\n",
    "        \"atRule\": \"\",\n",
    "        \"mediaQuery\": \"\"\n",
    "    }\n",
    "\n",
    "def getSelectorStyleMap(styles):\n",
    "    styles = np.array(styles.split(\"{\"))\n",
    "    styles = list(map(lambda selectorStyle: selectorStyle.split(\"}\"), styles))\n",
    "    styles = [j for sub in styles for j in sub] # empty string means end of an at rule\n",
    "    \n",
    "    selectorToStyle = {}\n",
    "    mediaQuery = \"\"\n",
    "    atRule = \"\"\n",
    "    isSelector = True\n",
    "\n",
    "    for i, cssComponent in enumerate(styles):\n",
    "        if \"@media\" in cssComponent:\n",
    "            mediaQuery = cssComponent\n",
    "            continue\n",
    "        elif \"@\" in atRule:\n",
    "            atRule = cssComponent\n",
    "            continue\n",
    "\n",
    "        if isSelector:\n",
    "            selectorToStyle[cssComponent] = None\n",
    "            isSelector = False\n",
    "        else:\n",
    "            selectorToStyle[styles[i-1]] = {\n",
    "                \"style\": list(map(lambda x: x.split(\":\"), cssComponent.split(\";\"))),\n",
    "                \"atRule\": atRule,\n",
    "                \"mediaQuery\": mediaQuery\n",
    "            }\n",
    "            isSelector = True\n",
    "\n",
    "    del selectorToStyle[\"\"]\n",
    "\n",
    "    return selectorToStyle\n",
    "\n",
    "def colorToHexCode(value):\n",
    "    try:\n",
    "        # error is caused with gradients\n",
    "        if \"hsla\" in value or \"rgba\" in value:\n",
    "            return value\n",
    "\n",
    "        # seperate hsl or rgb args\n",
    "        value = value.replace(\"%\", \"\")\n",
    "        colors = [int(x) for x in value[value.find(\"(\")+len(\"(\"):value.rfind(\")\")].split(\",\")]\n",
    "\n",
    "        # if hsl convert to rgb\n",
    "        if \"hsl\" in value:\n",
    "            h, s, l = colors\n",
    "            h = h/360\n",
    "            s = s/100\n",
    "            l = l/100\n",
    "            colors = colorsys.hls_to_rgb(h, l, s)\n",
    "            colors = [int(round(x*255.0)) for x in colors]\n",
    "\n",
    "        # convert rgb to hexcode\n",
    "        colors = list(map(lambda color: str(hex(color).split('x')[-1][-2:]).zfill(2), colors))\n",
    "        colors = \"\".join(colors)\n",
    "\n",
    "        return f\"#{colors}\"\n",
    "    except:\n",
    "        return value\n",
    "\n",
    "def seperateSizeValues(values):\n",
    "    values = values.replace(\" \", \"\")\n",
    "    values = values.replace(\"auto\", \"1auto\")\n",
    "\n",
    "    seperatedValues = []\n",
    "    value = \"\"\n",
    "    isUnit = False\n",
    "\n",
    "    for char in values:\n",
    "        if isUnit and char.isdigit():\n",
    "            isUnit = False\n",
    "            seperatedValues.append(value)\n",
    "            value = \"\"\n",
    "\n",
    "        value = f\"{value}{char}\"\n",
    "\n",
    "        if not char.isdigit():\n",
    "            isUnit = True\n",
    "\n",
    "    seperatedValues.append(value)\n",
    "\n",
    "    return [x if x != \"1auto\" else \"auto\" for x in seperatedValues]\n",
    "\n",
    "def sizeShortHandToLongHand(attr, seperatedValues):\n",
    "    try:\n",
    "        fourPosArgs = [[\"top\"], [\"right\"], [\"bottom\"], [\"left\"]]\n",
    "        threePosArgs = [[\"top\"], [\"left\", \"right\"], [\"bottom\"]]\n",
    "        twoPosArgs = [[\"top\", \"bottom\"], [\"left\", \"right\"]]\n",
    "\n",
    "        posArgs = [twoPosArgs, threePosArgs, fourPosArgs][len(seperatedValues)-2]\n",
    "\n",
    "        longHand = []\n",
    "\n",
    "        for i, pos in enumerate(posArgs):\n",
    "            for posName in pos:\n",
    "                longHand.append([f\"{attr}-{posName}\", seperatedValues[i]])\n",
    "\n",
    "        return longHand\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def normalizeStyle(attr, value):\n",
    "    isMultiSelectorChange = False\n",
    "\n",
    "    if \"color\" in attr:\n",
    "        if not \"#\" in value:\n",
    "           value = colorToHexCode(value)\n",
    "    elif attr == \"margin\" or attr == \"padding\":\n",
    "        isMultiSelectorChange = True\n",
    "        seperateValues = seperateSizeValues(value)\n",
    "\n",
    "        if seperateValues:\n",
    "            isMultiSelectorChange = False\n",
    "            attr, value = None, sizeShortHandToLongHand(attr, seperateValues)\n",
    "\n",
    "    return attr, value, isMultiSelectorChange\n",
    "\n",
    "def getStyleText(styleMap):\n",
    "    selectorStyles = [styleMap[key][\"style\"] for key in styleMap if not styleMap[key][\"atRule\"] and not styleMap[key][\"mediaQuery\"]]\n",
    "    styles = []\n",
    "\n",
    "    for selectorStyle in selectorStyles:\n",
    "        style = \"\"\n",
    "        for attr, value in selectorStyle:\n",
    "            style += f\"{attr}: {value}; \"\n",
    "        style = style.strip()\n",
    "\n",
    "        styles.append(style)\n",
    "\n",
    "    return styles\n",
    "\n",
    "def insertElementsByIndices(list_a, list_b, pos):\n",
    "    assert(len(list_b) == len(pos))\n",
    "    acc = 0\n",
    "    for i in range(len(list_b)):\n",
    "        list_a.insert(pos[i]+acc, list_b[i])\n",
    "        acc += 1\n",
    "\n",
    "    return list_a\n",
    "\n",
    "def getFinalStyleText(selector, styles):\n",
    "    if type(styles) is list:\n",
    "        return f\"{selector}{'{'}{''.join([f'{x[0]}:{x[1]};' for x in styles])}{'}'}\"\n",
    "    else:\n",
    "        return f\"{selector}{'{'}{styles}{'}'}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRefactoredCss(filePath):\n",
    "    backslash = \"\\\\\"\n",
    "    outputFilePath = f\"refactored-files{backslash}{filePath.replace(backslash, '-')}\"\n",
    "\n",
    "    with open(filePath, \"rb\") as file:\n",
    "        css_text_test = file.read().decode(errors=\"replace\")\n",
    "\n",
    "    styleMap = getSelectorStyleMap(css_text_test)\n",
    "\n",
    "    for selector in styleMap:\n",
    "        if selector:\n",
    "            for i, x in enumerate(styleMap[selector][\"style\"]):\n",
    "                try:\n",
    "                    attr, value = x\n",
    "                    a, v, isMultiSelectorChange = normalizeStyle(attr, value)\n",
    "\n",
    "                    if isMultiSelectorChange:\n",
    "                        del attr, value\n",
    "                        styleMap[selector][\"style\"].extend(v)\n",
    "                    else:\n",
    "                        attr, value = a, v\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "    if \"\" in styleMap:\n",
    "        del styleMap[\"\"]\n",
    "\n",
    "    # does not include styles in media queries\n",
    "    testStyles = getStyleText(styleMap)\n",
    "\n",
    "    runKmeans = True\n",
    "\n",
    "    selector_styles_df = None\n",
    "\n",
    "    if runKmeans:\n",
    "        vectorizer = TfidfVectorizer(stop_words={'english'})\n",
    "        X = vectorizer.fit_transform(testStyles)\n",
    "        \n",
    "        Sum_of_squared_distances = []\n",
    "        K = range(2, len(testStyles))\n",
    "        sil = []\n",
    "\n",
    "        timeout = time.time() + 60*5\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('error')\n",
    "            try:\n",
    "                for k in K:\n",
    "                    if time.time() > timeout:\n",
    "                        break\n",
    "                    km = KMeans(n_clusters=k, max_iter=10, n_init=10) # 150\n",
    "                    km = km.fit(X)\n",
    "                    Sum_of_squared_distances.append(km.inertia_)\n",
    "                    sil.append(silhouette_score(X, km.labels_, metric=\"euclidean\"))\n",
    "                    print(f\"Iteration: {k}/{len(testStyles)}\", end=\"\\r\")\n",
    "            except Warning:\n",
    "                print(\"Training stopped early due to convergence warning\")\n",
    "                pass\n",
    "\n",
    "        # plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "        # plt.xlabel('k')\n",
    "        # plt.ylabel('Sum_of_squared_distances')\n",
    "        # plt.title('Elbow Method For Optimal k')\n",
    "        # plt.show()\n",
    "\n",
    "        # rerunning this without the above cells will change the output values\n",
    "        selector = list(styleMap.keys())\n",
    "\n",
    "        true_k = sil.index(max(sil))+2\n",
    "        model = KMeans(n_clusters=true_k, init='k-means++', max_iter=200, n_init=10)\n",
    "        model.fit(X)\n",
    "        labels = model.labels_\n",
    "\n",
    "        selector_styles_df = pd.DataFrame(list(zip(selector,labels)),columns=['selector','cluster'])\n",
    "        selector_styles_df = selector_styles_df.sort_values(by=['cluster'])\n",
    "    else:\n",
    "        selector_styles_df = pd.read_json(\"selectors-clustered.json\")\n",
    "        selector_styles_df.columns = ['selector','cluster']\n",
    "\n",
    "    if runKmeans:\n",
    "        saveAsJson(f\"{outputFilePath[:-4]}.json\", selector_styles_df.values.tolist())\n",
    "\n",
    "    clusteredSelectors = selector_styles_df.values.tolist()\n",
    "    clusterSelectorMap = {}\n",
    "\n",
    "    for selector, clusterIndex in clusteredSelectors:\n",
    "        if str(clusterIndex) in clusterSelectorMap:\n",
    "            clusterSelectorMap[str(clusterIndex)].append(selector)\n",
    "        else:\n",
    "            clusterSelectorMap[str(clusterIndex)] = [selector]\n",
    "\n",
    "    unsortedCombinedStyleMap = {}\n",
    "\n",
    "    for clusterIndex in clusterSelectorMap:\n",
    "        sharedStyles = {}\n",
    "        sharedValues = {}\n",
    "\n",
    "        for selector in clusterSelectorMap[clusterIndex]:\n",
    "            for attr, value in styleMap[selector][\"style\"]:\n",
    "                style = f\"{attr.strip()}: {value.strip()};\"\n",
    "\n",
    "                if style in sharedStyles:\n",
    "                    sharedStyles[style].append(selector)\n",
    "                else:\n",
    "                    sharedStyles[style] = [selector]\n",
    "        \n",
    "        for style in sharedStyles:\n",
    "            combinedSelector = \", \".join(sharedStyles[style])\n",
    "            unsortedCombinedStyleMap[combinedSelector] = style\n",
    "\n",
    "    combinedSelectorOrder = []\n",
    "\n",
    "    for combinedSelector in unsortedCombinedStyleMap:\n",
    "        selectors = combinedSelector.split(\", \")\n",
    "        mapKeys = list(styleMap.keys())\n",
    "        order = [mapKeys.index(selector) for selector in selectors]\n",
    "        \n",
    "        combinedSelectorOrder.append((min(order), combinedSelector))\n",
    "\n",
    "    combinedSelectorOrder.sort(key=lambda x: x[0])\n",
    "    combinedSelectorOrder\n",
    "\n",
    "    selectorOrder = [x[0] for x in combinedSelectorOrder]\n",
    "    selectorStylesInOrder = [[x[1], getDefaultStyleProps(unsortedCombinedStyleMap[x[1]])] for x in combinedSelectorOrder]\n",
    "    selectorStylesInOrder\n",
    "\n",
    "    for selector, styleProps in selectorStylesInOrder:\n",
    "        selectors = selector.split(\", \")\n",
    "        styles = [x for x in styleProps[\"style\"].split(\";\") if x != \"\"]\n",
    "        \n",
    "        for i, style in enumerate(styles):\n",
    "            styles[i] = style.replace(\" \", \"\").split(\":\")\n",
    "\n",
    "        for selector in selectors:\n",
    "            if selector in styleMap:\n",
    "                for i, originalStyle in enumerate(styleMap[selector][\"style\"]):\n",
    "                    a1, v1 = originalStyle\n",
    "                    for a2, v2 in styles:\n",
    "                        if a1 == a2 and v1 == v2:\n",
    "                            del styleMap[selector][\"style\"][i]\n",
    "\n",
    "    styles = [[selector, styleMap[selector]] for selector in styleMap]\n",
    "    styles = insertElementsByIndices(styles, selectorStylesInOrder, selectorOrder)\n",
    "\n",
    "    refactoredCssText = \"\"\n",
    "\n",
    "    for selector, styleProps in styles:\n",
    "        if not styleProps[\"atRule\"] == \"\" or len(styleProps[\"style\"]) == 0:\n",
    "            continue\n",
    "\n",
    "        if styleProps[\"mediaQuery\"] == \"\":\n",
    "            refactoredCssText += getFinalStyleText(selector, styleProps[\"style\"])\n",
    "        else:\n",
    "            refactoredCssText += f\"{styleProps['mediaQuery']}{'{'}{getFinalStyleText(selector, styleProps['style'])}{'}'}\"\n",
    "\n",
    "    with open(outputFilePath, \"w\") as f:\n",
    "        f.write(refactoredCssText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early due to convergence warning\n"
     ]
    }
   ],
   "source": [
    "generateRefactoredCss(\"minified-dataset\\\\Facebook\\\\index_files\\\\1GsqYFnXaZQ.css\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Training stopped early due to convergence warning\n",
      "Number of files refactored: 191\r"
     ]
    }
   ],
   "source": [
    "errorCount = 0\n",
    "\n",
    "for i, (filePath, dirs, files) in enumerate(os.walk(\"minified-dataset\")):\n",
    "    for file in files:\n",
    "        try:\n",
    "            generateRefactoredCss(os.path.join(filePath, file))\n",
    "            print(f\"Number of files refactored: {i}\", end=\"\\r\")\n",
    "        except:\n",
    "            errorCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorCount"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a46f0e7d7db2b4b2704a15e4e0b2e33d73549edf512530e310df04cf4d31824c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
